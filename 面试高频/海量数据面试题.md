## 如何从100万个数中找出最大的前100个数

算法如下：根据快速排序划分的思想 
(1) 递归对所有数据分成[a,b）b（b,d]两个区间，(b,d]区间内的数都是大于[a,b)区间内的数 
(2) 对(b,d]重复(1)操作，直到最右边的区间个数小于100个。注意[a,b)区间不用划分 
(3) 返回上一个区间，并返回此区间的数字数目。接着方法仍然是对上一区间的左边进行划分，分为[a2,b2）b2（b2,d2]两个区间，取（b2,d2]区间。如果个数不够，继续(3)操作，如果个数超过100的就重复1操作，直到最后右边只有100个数为止。 

2.先取出前100个数，维护一个100个数的最小堆，遍历一遍剩余的元素，在此过程中维护堆就可以了。具体步骤如下： 
step1：取前m个元素（例如m=100），建立一个小顶堆。保持一个小顶堆得性质的步骤，运行时间为O（lgm);建立一个小顶堆运行时间为m*O（lgm）=O(m lgm);       
step2:顺序读取后续元素，直到结束。每次读取一个元素，如果该元素比堆顶元素小，直接丢弃 
如果大于堆顶元素，则用该元素替换堆顶元素，然后保持最小堆性质。最坏情况是每次都需要替换掉堆顶的最小元素，因此需要维护堆的代价为(N-m)*O(lgm); 
最后这个堆中的元素就是前最大的10W个。时间复杂度为O(N lgm）。 




补充：这个方法的说法也可以更简化一些：
假设数组arr保存100个数字，首先取前100个数字放入数组arr，对于第101个数字k，如果k大于arr中的最小数，则用k替换最小数，对剩下的数字都进行这种处理。

3.分块查找 

先把100w个数分成100份，每份1w个数。先分别找出每1w个数里面的最大的数，然后比较。找出100个最大的数中的最大的数和最小的数，取最大数的这组的第二大的数，与最小的数比较。。。。

https://blog.csdn.net/cslbupt/article/details/65935577

## 100G 数据，只有 100M 内存，怎么排序？

![这里写图片描述](https://img-blog.csdn.net/20180816160545465?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0NsZXZlckNvZGU=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

100G 数据，按照 100M 内存拆分，然后排序有序的数据，然后写入到 file1,file2…file100。（**内部有序，多路归并**）
多路归并。
第一回合：
从 file1,file2,file3…file100.取出第一个数。及最小的。所有的初始指针都是第一行。
min1=min(min1 = min(min1=min(fil1,file2,file3…file100)；
min1写入到大数据文件。大数据行数指针+1。min1 写入到大数据文件。大数据行数指针+1。min1写入到大数据文件。大数据行数指针+1。min1 对应的行数指针+1。



第二回合：
从 file1,file2,file3…file100.取出第一个数。及最小的。所有的初始指针都是第一行。
min2=min(min2 = min(min2=min(fil1,$file2,file3…file100)；
min2写入到大数据文件。大数据行数指针+1。min2 写入到大数据文件。大数据行数指针+1。min2写入到大数据文件。大数据行数指针+1。min2 对应的行数指针+1。

## [100亿个数字找出最大的10个](https://www.cnblogs.com/nzbbody/p/3576894.html)

1、首先一点，对于海量数据处理，思路基本上是确定的，必须分块处理，然后再合并起来。

2、对于每一块必须找出10个最大的数，因为第一块中10个最大数中的最小的，可能比第二块中10最大数中的最大的还要大。

3、分块处理，再合并。也就是Google MapReduce 的基本思想。Google有很多的服务器，每个服务器又有很多的CPU，因此，100亿个数分成100块，每个服务器处理一块，1亿个数分成100块，每个CPU处理一块。然后再从下往上合并。注意：分块的时候，要保证块与块之间独立，没有依赖关系，否则不能完全并行处理，线程之间要互斥。另外一点，分块处理过程中，不要有副作用，也就是不要修改原数据，否则下次计算结果就不一样了。

## bloom filter

如果想判断一个元素是不是在一个集合里，一般想到的是将集合中所有元素保存起来，然后通过比较确定。[链表](https://zh.wikipedia.org/wiki/链表)、[树](https://zh.wikipedia.org/wiki/树_(数据结构))、[散列表](https://zh.wikipedia.org/wiki/散列表)（又叫哈希表，Hash table）等等数据结构都是这种思路。但是随着集合中元素的增加，我们需要的存储空间越来越大。同时检索速度也越来越慢。

布隆过滤器的原理是，当一个元素被加入集合时，通过K个[散列函数](https://zh.wikipedia.org/wiki/散列函数)将这个元素映射成一个位[数组](https://zh.wikipedia.org/wiki/数组)中的K个点，把它们置为1。检索时，我们只要看看这些点是不是都是1就（大约）知道集合中有没有它了：如果这些点有任何一个0，则被检元素一定不在；如果都是1，则被检元素很可能在。这就是布隆过滤器的基本思想。

**优点**

相比于其它的数据结构，布隆过滤器在空间和时间方面都有巨大的优势。布隆过滤器存储空间和插入/查询时间都是常数O(k)。另外，散列函数相互之间没有关系，方便由硬件并行实现。布隆过滤器不需要存储元素本身，在某些对保密要求非常严格的场合有优势。

布隆过滤器可以表示全集，其它任何数据结构都不能；

**缺点**

但是布隆过滤器的缺点和优点一样明显。误算率是其中之一。随着存入的元素数量增加，误算率随之增加。但是如果元素数量太少，则使用散列表足矣。

1. 误算率在数据量比较大时会比较高
2. 删除元素困难，首先我们必须保证删除的元素的确在布隆过滤器里面。这一点单凭这个过滤器是无法保证的。