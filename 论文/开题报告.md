



## 摘要



### 背景

为什么要使用区块链系统？

相比比特币以太坊的智能合约有什么优势?

以太坊平台中的数据为什么有价值？

信任是人类社会的基石，但是在一个社会中不能保证每一个人都是完全诚实，总会有一些"作恶"的个体存在，因此如何保证作恶的个体不会影响整个社会的正常运行时人们自古以来一直研究的问题。比如1982年由[莱斯利·兰波特](https://zh.wikipedia.org/wiki/莱斯利·兰波特)提出的拜占庭将军问题[1]就是一个典型的容错性问题。

2008年一个别称中本聪的密码朋克在网上发布了一篇关于点对点的现金交易系统的论文引出了区块链系统[2]，在早期比特币是区块链的代表。区块链是由多种技术组合而成的技术，密码学技术，共识机制，点对点传输，分布式账本等等。区块链通过融合这些技术来解决系统中每个个体之间的信任问题，区块链系统的本质就是通过数学运算作为保障来降低人类的信任成本。人们最近开始大量关注区块链技术不仅仅是因为其技术发展带来的比较竞争优势，而是更多的考虑这种技术对于社区治理和经济生产带来的深刻变革。

以太坊[3]是在比特币基础上发展而来的新型区块链系统，被称为区块链2.0，它相比于比特币无论在创新的广度和深度上都有巨大的优势。以太坊相比于比特币的最大优势是具备图灵完备性[4]，其创新性的引入的智能合约[3]的概念，实现了"code is law"的伟大构想。但是随着以太坊上智能合约增多，目前采用solidity[5]编写的智能合约就有超过200万个，并且每天都在不断地增加，以太坊平台通过软分叉的手段来增加出块速度和增大每一块的容量来提高链上的TPS，这也导致了其产生的区块数据也开始大量增加，虽然以太坊主链上线时间比比特币晚了6年左右，但是其区块数据量已经远远多于比特币的数据量。以太坊上产生的数据相比于一般数据而言具有真实性和不可篡改性，通过这些数据可以分析用户和智能合约的行为，来统计出一些恶意的行为，以及分析当前以太坊上流行的行为和某一种ERC20[6]代币的交易情况。

综上分析以太坊平台上的链上数据具有重大价值，为了达到上述的研究目的，主要面临以下挑战：

1. 本地重放交易的效率低。因为链上的数据只是保留区块的数据，没有保留区块运行时的中间状态。在同步区块到本地后，在本地的EVM上运行交易时因为要获取交易的中间状态，导致交易重放的效率底下。因此需要优化本地的EVM重放交易的过程。
2. 数据库优化。获取链上数据中间状态后，需要将中间状态存储到数据库中，但是由于中间状态的数据量较大，需要对存储进数据库的数据进行存储优化。
3. 如何对用户和合约行为进行分析。当获取到交易的中间数据后采用何种方法和角度对中间数据进行分析。

#### 国内外的发展现状

中山大学陈伟利和郑子彬总结了当前的区块链数据分析的成果,在介绍区块链技术架构和关键技术的基础上,分析了目前区块链系统中主要的数据类型,总结了目前区块链数据的分析方法,并就实体识别、隐私泄露风险分析、网络画像、网络可视化、市场效应分析、交易模式识别、非法行为检测与分析等7个问题[7]，但是在对以太坊的数据分析上仅仅停留在使用爬虫在etherscan网站上爬取智能合约的内部交易数据进行数据分析，并且etherscans网站对API做了限制，每次只能获取10000笔交易，这样的做法大大减慢了数据获取的速度和降低了数据的丰富性。

[Anton I. Badev](https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=432841)和[Matthew Chen](https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=1873061)[8]对比特币的用户行为和交易进行了分析，提取了比特币交易中的一些异常行为，并且对于这些行为给出了合理的解释。但是并没有对以太坊平台的数据进行分析。

中山大学陈伟利和郑子斌等在2018年通过使用爬虫爬取etherscan网站上ethereum的所有智能合约，然后对合约的内容操作码进行分析，来找到以太坊平台上的庞氏骗局合约[9]。这种方法同样有着速度获取慢，数据真实性存疑，数据丰富性不足。



以太坊系统上智能合约相关的内部交易数据, 但由于API的限制, 只能获取每个账户最近10 000笔的交易.

#### 参考文献

[1]L. Lamport, R. Shostak and M. Pease, "The Byzantine Generals Problem", *ACM Transactions on Programming Languages and Systems*, vol. 4, no. 3, pp. 382-401, 1982. Available: 10.1145/357172.357176.

[2]C. Wright, "Bitcoin: A Peer-to-Peer Electronic Cash System", *SSRN Electronic Journal*, 2008. Available: 10.2139/ssrn.3440802.

[3]Cryptorating.eu. (2019). [online] Available at: https://cryptorating.eu/whitepapers/Ethereum/Ethereum_white_paper.pdf [Accessed 8 Dec. 2019].

[4]"ethereum/wiki", *GitHub*, 2019. [Online]. Available: https://github.com/ethereum/wiki/wiki/White-Paper. [Accessed: 08- Dec- 2019].

[5] Solidity.readthedocs.io. (2019). *Solidity — Solidity 0.5.14 documentation*. [online] Available at: https://solidity.readthedocs.io/en/develop [Accessed 8 Dec. 2019].

[6]Proposals, E. (2019). *EIP 20: ERC-20 Token Standard*. [online] Ethereum Improvement Proposals. Available at: https://eips.ethereum.org/EIPS/eip-20 [Accessed 8 Dec. 2019].

[7]陈伟利,郑子彬.区块链数据分析:现状、趋势与挑战[J].计算机研究与发展,2018,55(09):1853-1870.

[8]Badev, A. and Chen, M. (2014). Bitcoin: Technical Background and Data Analysis. *SSRN Electronic Journal*.

[9]Detecting Ponzi Schemes on Ethereum: Towards Healthier Blockchain Technology

#### 课题内容和具体方案

为了解决以太坊平台海量区块数据处理利用难和合约状态监控难的问题，本文拟提出一种链上状态高速抽取重放和分析处理技术。从而为区块链大数据分析和链上数据治理提供可能。具体内容包括以下几个部分：

1. 启动一个全节点，同步区块数据到本地，在本地构建一个改进后的EVM虚拟机，将每个区块中的交易进行重放，提取出交易执行的中间状态，并且将中间状态进行存储。
2. 将存储的中间状态导入到数据库，由于中间状态的数据量较大，并且关于区块链上的ERC20数据都是涉及金融行业的数据，对数据的准确性和完整性要求较高，因此需要对中间数据的存储进行深层次的优化。
3. 基于数据库中的中间状态数据进行用户和智能合约的行为进行实时分析，检测出一些恶意用户行为和恶意合约。比如重入攻击会导致合约之间循环调用的情况，我们可以通过trace的数量和trace中callcode操作码的数量进行分析恶意的用户行为和恶意合约。



#### 工作大致安排

2019.12-2020.1 完成本地重放智能合约的优化工作，加快本地重放合约的速度。

2020.1-2020.2   完成中间数据在数据库的优化工作

2020.2-2020.4   完成中间数据的实时分析，并且撰写小论文。

2020.4-2020.7   修改小论文，开始着手毕业论文论文的写作

2020.7-2020.10  完成毕业论文的写作

2020.10-2021.3  准备毕业答辩



#### 预期成果

完成小论文一篇

\1.  以太坊数据获取的速度受限和完整性以及丰富度存在不足。调用第三方平台etherscan的API受限，并且其API获取的数据不够丰富，不足以满足深入分析需求。本地抽取智能合约中间状态和高效重放智能合约能够再本地获取丰富数据，解决区块链海量数据处理难的问题。

\2.  Ethereum-etl工具直接从全节点取数据，一定程度上优于从etherscan第三方数据平台上获取数据，但是这样也存在数据获取慢的问题。提供RPC服务的全节点需要使用面向区块链的数据缓存同步技术进行数据查询优化。



\1.     本地重放交易的效率低。因为链上的数据只是保留区块的数据，没有保留区块运行时的中间状态。在同步区块到本地后，在本地的EVM上运行交易时因为要获取交易执行的中间状态，导致交易重放的效率底下。因此需要优化本地的EVM重放交易的过程。

\2.     数据库优化。获取链上数据中间状态后，需要将中间状态存储到数据库中，但是由于中间状态的数据量较大，需要对存储进数据库的数据进行存储优化。

\3.     如何对用户和合约行为进行分析。当获取到交易的中间数据后采用何种方法和角度对中间数据进行分析。







\1.  研究以太坊EVM虚拟机的运行机理，在本地基于以太坊虚拟机进行改进，使得每个区块中的每笔交易重放过程中抽取一些关键的中间数据，并且使得运行过程保持高效(每一次运行数据的关注点不同，导致抽取的中间数据不同)。

\2.  将交易计算的中间状态导入到数据库，由于中间状态的数据量较大，并且关于区块链上的ERC20数据都是涉及金融行业的数据，对数据的准确性和完整性要求较高，因此需要对中间数据的存储进行深层次的优化。

\3.  基于数据库中的中间状态数据进行用户和智能合约的行为进行实时分析，检测出一些恶意用户行为和恶意合约。比如重入攻击会导致合约之间循环调用的情况，可以通过trace的数量和trace中callcode操作码的数量进行分析恶意的用户行为和恶意合约。

1. 合约重放速度很慢。四种的优化过程。
2. 数据库查询的优化过程。
3. 基于数据对合约数据进行实时分析。



### 背景 

合约重放速度很慢，原因。要重复的构建世界状态。没有保存完整的世界状态。以太坊的账户体系和激励导致了合约熟读重放很慢。

数据库，数据量很大，举例子   数据量恨到  稳定币交易量非常大，1000W稳定币数量镇长熟读很快，必须要做一些精准数据，因为涉及到一些财务的状态，数据量应该非常精准，金融数据是非常重要的。实时数据的查询。

合约分析：做合约和用户行为分析，链上一些金融情况，一些安全事件的监控。



### 研究内容

简短



### 路线

参考文献

分析同步机理，诊断哪里有问题

数据分析优化：

为什么要优化，实时，分库分表，数据分片，数据组织分布式，缓冲的合理建立，索引技术

一些重点合约的监控，对trace的行为进行分析，可以检测一些异常的trace。对于攻击状态进行分析。



证明某个结论来支持你的观点，可以通过参考文献来证明你的观点。

status 

CumulativeGasUsed

Logs

TxHash

...

blockNumber

TransactionIndex





然而区块链是一个开放或者半开方的系统，部署后的智能合约代码难以修改或者升级，合约细节也对攻击者暴露无遗。一旦智能合约出现安全漏洞，将会遭受难以想象的损失。智能合约数量的增加也导致区块数据的增加，虽然以太坊主链上线时间比比特币晚了6年左右，但是其区块数据量已经远远多于比特币的数据量。区块链上产生的数据相比于一般数据而言具有真实性和不可篡改性，通过这些数据可以分析用户和智能合约的行为，来分析交易攻击通常具备的参数和行为，统计恶意地址以及通过利用重放智能合约获取的合约外部调用热点图，进而得到近期的热门合约和高价值合约，对这些合约进行重点分析和监控。++



### 泊松分布

单位时间内随机事件发生次数的概率分布



首先根据块信息构造一个种子，使用这个种子计算出一个16M的cache数据，轻客户端需要存储这份cache，通过cache计算出一个1GB(初始大小)的数据集，挖矿过程中需要从DAG中反复重复随机抽取数据和其他元素计算mixhash，DAG中每个元素的生成只依赖于cache中的少量数据。每个纪元的DAG会完全不一样，并且它的时间也随着时间线性增长。



[Anton I. Badev](https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=432841)和[Matthew Chen](https://papers.ssrn.com/sol3/cf_dev/AbsByAuth.cfm?per_id=1873061)

